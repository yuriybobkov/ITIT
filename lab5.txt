public class Main { 
 
 public static void main(String[] args) throws IOException {   System.out.println("Start...");      System.out.println("\nPrepocessing Training data");   String class1 = "<=50K", class2 = ">50K";   ArrayList<Integer> continuousAttributes = new ArrayList<>();   continuousAttributes.add(0);   continuousAttributes.add(2);   continuousAttributes.add(4);   continuousAttributes.add(10);   continuousAttributes.add(11);   continuousAttributes.add(12);      Preprocess p = new Preprocess(class1, class2, continuousAttributes);   ArrayList<String[]> trainData = p.discretize(new File("train.data"));   int noOfClass1 = p.c1, noOfClass2 = p.c2;   Preprocess.predictMissingValues(trainData, "train"); 
     Preprocess.computeDiscreteValues(trainData);      System.out.println("\nPrepocessing Testing data");   ArrayList<String[]> testData = Preprocess.preprocessTestData(new File("test.data"), continuousAttributes);      ArrayList<Integer> remAttr = new ArrayList<>();   for(int i = 0; i < trainData.get(0).length-1; i++) remAttr.add(i);   System.out.println("\nGenerating Decision Tree using ID3 Algorithm");   //<=50K = class1, >50K = class2   ID3 decisionTree = new ID3(trainData, testData, noOfClass1, noOfClass2, class1, class2, Preprocess.discreteValues, remAttr);   decisionTree.printTrainingTime();   decisionTree.printAnalysis();      System.out.println("\nApplying Reduced Error Pruning on the decision tree generated");   //if you want to preserve original tree then create another ID3 instance and pass that to rep   ReducedErrorPruning rep = new ReducedErrorPruning(decisionTree);   rep.tree.printAnalysis();      int noOftrees = 10;   double fractionOfAttributesToTake = 0.5, fractionOfTrainingInstancesToTake = 0.33;   System.out.println("\nInitializing Random Forest with "+noOftrees+" trees, "+fractionOfAttributesToTake     +" fraction of attributes and "+fractionOfTrainingInstancesToTake+" fraction of training instances in each tree");   RandomForest rf = new RandomForest(noOftrees, fractionOfAttributesToTake, fractionOfTrainingInstancesToTake,      trainData, testData, noOfClass1, noOfClass2, class1, class2, Preprocess.discreteValues);   rf.printAnalysis();      System.out.println("\nEnd...");  } } 
 
Τΰιλ ID3.java 
 
import java.util.ArrayList; import java.util.HashMap; 
 
public class ID3 {  HashMap<Integer, ArrayList<String>> discreteValues;  String class1, class2;  ArrayList<String[]> data, testData;//data = training data  Node root;  double trainingTime=0, precision, recall, fscore, accuracy;  int noOfNodes;    public ID3(ArrayList<String[]> data, ArrayList<String[]> testData, int noOfClass1, int noOfClass2, String class1, String class2, HashMap<Integer, ArrayList<String>> discreteValues, ArrayList<Integer> remAttr){   trainingTime = System.currentTimeMillis();      this.data = data;   this.class1 = class1;   this.class2 = class2;   this.testData = testData;   this.discreteValues = discreteValues; 
     root = new Node();   double p1 = noOfClass1/(noOfClass1+noOfClass2+0.0), p2 = noOfClass2/(noOfClass1+noOfClass2+0.0);   root.entropy = -1*pLogP(p1) - 1*pLogP(p2);   root.data = data;   root.noOfClass1 = noOfClass1;   root.noOfClass2 = noOfClass2;      root.remainingAttributes = remAttr;   generateDecisionTree(root);      trainingTime = (System.currentTimeMillis() - trainingTime)/1000.0;      analyse();//calculate precision, recall, fscore, accuracy  }    public void analyse(){   int correctClassification=0, incorrectClassification=0;   int truePositive = 0, falsePositive = 0, falseNegative = 0;   for(String[] s : testData){    int predicted = Node.predictClass(root, s, discreteValues), actual = s[s.length-1].equals(class1)?1:2;    if(predicted  == actual ) correctClassification++;    else       incorrectClassification++;        //1-->yes, 2-->no    if(predicted==1 && actual==1)   truePositive++;    else if(predicted==1 && actual==2)  falseNegative++;    else if(predicted==2 && actual==1)  falsePositive++;   }   precision = truePositive/(truePositive+falsePositive+0.0);   recall = truePositive/(truePositive+falseNegative+0.0);   fscore = 2*precision*recall/(precision+recall);   accuracy = (correctClassification)/(correctClassification+incorrectClassification+ 0.0);      noOfNodes = 0;   countNodes(root);  }    public void printAnalysis(){   System.out.println("Accuracy="+accuracy+"\nPrecision="+precision+" Recall="+recall+" F-Score="+fscore);   System.out.println("No of nodes in tree = "+noOfNodes);  }    public void printTrainingTime(){   System.out.println("Training Time="+trainingTime+"secs");  }    public void countNodes(Node root){   if(root==null) return;   noOfNodes++;   if(root.isLeaf) return;   for(Node n : root.children) countNodes(n);  }    private static double pLogP(double p){   return p==0?0:p*Math.log(p);  }    private void generateDecisionTree(Node root){   if(root==null) return; 
  if(root.remainingAttributes.size()==1){//leaf node    root.isLeaf = true;    root.classification = root.noOfClass1>=root.noOfClass2?1:2;   }else if(root.noOfClass1==0 || root.noOfClass2==0 || root.data.size()==0){//leaf    root.isLeaf = true;    root.classification = root.noOfClass1==0?2:1;   }else{    //find split attribute which gives max gain    root.children = splitAttribute(root);    ArrayList<String> discreteValuesOfThisAttribute = discreteValues.get(root.attribute);    for(int j=0; j < discreteValuesOfThisAttribute.size(); j++){     root.children[j].data = new ArrayList<>();     root.children[j].remainingAttributes = new ArrayList<>();     for(int rem : root.remainingAttributes){      if(rem!=root.attribute) root.children[j].remainingAttributes.add(rem);     }     String curr = discreteValuesOfThisAttribute.get(j);     for(String[] s : root.data){      if(s[root.attribute].equals(curr)){       root.children[j].data.add(s);      }     }     generateDecisionTree(root.children[j]);    }   }  }    public Node[] splitAttribute(Node root){   double maxGain = -1.0;   Node[] ans = null;   for(int i : root.remainingAttributes){    ArrayList<String> discreteValuesOfThisAttribute = discreteValues.get(i);    Node[] child = new Node[discreteValuesOfThisAttribute.size()];    for(int j=0; j < discreteValuesOfThisAttribute.size(); j++){     String curr = discreteValuesOfThisAttribute.get(j);     child[j] = new Node();     for(String[] s : root.data){      if(s[i].equals(curr)){       if(s[s.length-1].equals(class1)) child[j].noOfClass1++;       else         child[j].noOfClass2++;      }     }    }    int total = root.data.size();    double gain = root.entropy;    for(int j = 0; j < discreteValuesOfThisAttribute.size(); j++){     int c1 = child[j].noOfClass1, c2 = child[j].noOfClass2;     if(c1==0 && c2==0) continue;     double p1 = c1/(c1+c2+0.0), p2 = c2/(c1+c2+0.0);     child[j].entropy = -1*pLogP(p1) + -1*pLogP(p2);     gain -= ((c1+c2)/(total+0.0))*child[j].entropy;    }    if(gain > maxGain){     root.attribute = i;     maxGain = gain;     ans = child;    }   } 
  return ans;  } } 